# GenAI-LLMapps-lifecycle-workshop
 Hands-on workshop for end-to-end LLM lifecycle using Azure AI platform.

## Workshop Overview
 This workshop provides hands-on experience with the end-to-end lifecycle of Large Language Model (LLM) applications using Azure AI platform. The workshop covers the LLM application development lifecycle shown in the below diagram.

 <img src="common/images/llm_lifecycle.png" align="center" />

 ## Lab Scenarios
 This workshop provides hands-on experience with the following scenarios:
 1. Create a hybrid search solution using Azure AI Search that includes vector search.
 2. Create a RAG (Retrieval Augmented Generation) application using PromptFlow in Azure AI Studio.
 3. Test & evaluate RAG application using PromptFlow in Azure AI Studio.
 4. Deploy RAG application and consume it using REST API.

 Lab instructions and resources are provided in the respective folders.

Diagram below depicts the Azure AI platform components used in the workshop scenarios.
 <img src="common/images/azure_platform_workshop.png" align="center" />

 ## Workshop Prerequisites
 1. Azure subscription.
 2. Access to Azure OpenAI service.
 3. Azure AI Search service
 4. Azure Storage account.

## Additional Resources
- [Advance your maturity level for Large Language Model Operations (LLMOps)] (https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/concept-llmops-maturity)
- [What is Azure AI Studio?] (https://learn.microsoft.com/en-us/azure/ai-studio/what-is-ai-studio)
- [Custom Conversation Copilot application using multimodal AI] (https://github.com/amulchapla/AI-Conversational-Copilot)